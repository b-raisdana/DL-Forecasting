{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:32:05.571769Z",
     "start_time": "2024-10-11T10:32:01.782545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PanderaDFM.OHLCV import MultiTimeframeOHLCV\n",
    "from helper.data_preparation import single_timeframe\n",
    "from helper.helper import date_range_to_string\n",
    "from Config import config\n",
    "\n",
    "config.processing_date_range = date_range_to_string(start=pd.to_datetime('03-01-24'),\n",
    "                                                    end=pd.to_datetime('09-01-24'))\n",
    "# devided by rolling mean, std\n",
    "n_mt_ohlcv = pd.read_csv(\n",
    "    os.path.join(r\"C:\\Code\\dl-forcasting\\data\\Kucoin\\Spot\\BTCUSDT\",\n",
    "                 f\"n_mt_ohlcv.{config.processing_date_range}.csv.zip\"), compression='zip')\n",
    "n_mt_ohlcv"
   ],
   "id": "9caca9023e737e7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mDEBUG@\u001B[94m10-11.14:02:03:\u001B[92m...Starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       timeframe                       date      open     close      high  \\\n",
       "0          15min  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "1             1D  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "2             1h  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "3           1min  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "4             4h  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "...          ...                        ...       ...       ...       ...   \n",
       "341347        1D  2024-09-01 00:00:00+00:00 -0.684385 -1.265078 -1.114403   \n",
       "341348        1h  2024-09-01 00:00:00+00:00 -0.081138 -0.165222 -0.038223   \n",
       "341349      1min  2024-09-01 00:00:00+00:00 -0.018025 -0.275889 -0.122945   \n",
       "341350        4h  2024-09-01 00:00:00+00:00 -0.116954 -0.577484 -0.395726   \n",
       "341351      5min  2024-09-01 00:00:00+00:00  0.019726  0.277921  0.054425   \n",
       "\n",
       "             low    volume  \n",
       "0            NaN       NaN  \n",
       "1            NaN       NaN  \n",
       "2            NaN       NaN  \n",
       "3            NaN       NaN  \n",
       "4            NaN       NaN  \n",
       "...          ...       ...  \n",
       "341347 -0.900461  0.298451  \n",
       "341348 -0.001254 -0.095335  \n",
       "341349 -0.169871 -0.171993  \n",
       "341350 -0.480249  0.044290  \n",
       "341351  0.034553 -0.011040  \n",
       "\n",
       "[341352 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeframe</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15min</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1h</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1min</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4h</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341347</th>\n",
       "      <td>1D</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>-0.684385</td>\n",
       "      <td>-1.265078</td>\n",
       "      <td>-1.114403</td>\n",
       "      <td>-0.900461</td>\n",
       "      <td>0.298451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341348</th>\n",
       "      <td>1h</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>-0.081138</td>\n",
       "      <td>-0.165222</td>\n",
       "      <td>-0.038223</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>-0.095335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341349</th>\n",
       "      <td>1min</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>-0.018025</td>\n",
       "      <td>-0.275889</td>\n",
       "      <td>-0.122945</td>\n",
       "      <td>-0.169871</td>\n",
       "      <td>-0.171993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341350</th>\n",
       "      <td>4h</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>-0.116954</td>\n",
       "      <td>-0.577484</td>\n",
       "      <td>-0.395726</td>\n",
       "      <td>-0.480249</td>\n",
       "      <td>0.044290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341351</th>\n",
       "      <td>5min</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>0.277921</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.034553</td>\n",
       "      <td>-0.011040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341352 rows Ã— 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:32:06.004984Z",
     "start_time": "2024-10-11T10:32:05.725676Z"
    }
   },
   "cell_type": "code",
   "source": "n_mt_ohlcv.describe()",
   "id": "db6e26c4e54b9820",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                open          close           high            low  \\\n",
       "count  340668.000000  340668.000000  340668.000000  340668.000000   \n",
       "mean        0.002571       0.002537       0.000586       0.004814   \n",
       "std         1.080184       1.080047       1.081013       1.083676   \n",
       "min       -11.829250     -11.796538     -10.789105     -12.271370   \n",
       "25%        -0.556785      -0.557024      -0.575532      -0.531490   \n",
       "50%         0.010991       0.010835      -0.014932       0.036296   \n",
       "75%         0.575594       0.574331       0.553501       0.591531   \n",
       "max        13.730087      13.773854      13.686195      12.303279   \n",
       "\n",
       "              volume  \n",
       "count  340668.000000  \n",
       "mean        0.011528  \n",
       "std         1.070377  \n",
       "min        -4.911268  \n",
       "25%        -0.405402  \n",
       "50%        -0.136793  \n",
       "75%         0.143095  \n",
       "max        15.969589  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>0.011528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.080184</td>\n",
       "      <td>1.080047</td>\n",
       "      <td>1.081013</td>\n",
       "      <td>1.083676</td>\n",
       "      <td>1.070377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-11.829250</td>\n",
       "      <td>-11.796538</td>\n",
       "      <td>-10.789105</td>\n",
       "      <td>-12.271370</td>\n",
       "      <td>-4.911268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.556785</td>\n",
       "      <td>-0.557024</td>\n",
       "      <td>-0.575532</td>\n",
       "      <td>-0.531490</td>\n",
       "      <td>-0.405402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>-0.014932</td>\n",
       "      <td>0.036296</td>\n",
       "      <td>-0.136793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.575594</td>\n",
       "      <td>0.574331</td>\n",
       "      <td>0.553501</td>\n",
       "      <td>0.591531</td>\n",
       "      <td>0.143095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.730087</td>\n",
       "      <td>13.773854</td>\n",
       "      <td>13.686195</td>\n",
       "      <td>12.303279</td>\n",
       "      <td>15.969589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multi timeframe modelling\n",
    "\n",
    "\n",
    "structure_timeframes = {\n",
    "    '1W':{        pattern: '1D',        trigger: '4h',        double: '15min',    }, \n",
    "    '1D':{        pattern: '4h',        trigger: '1h',        double: '5min',    }, \n",
    "    '4h':{        pattern: '1h',        trigger: '15min',        double: '1min',    }, \n",
    "}\n",
    "n_mt_ohlcv include open, high, low, close, and volume of all timeframes.\n",
    "single_timeframe(n_mt_ohlcv, timeframe) will return data of specified timeframe.\n",
    "using tensorflow create 4 parallel CNN-LSTM models each fed with structure, pattern, trigger, and double timeframe data.\n",
    "join these parallel models together.\n"
   ],
   "id": "6427f865497c1ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:32:27.124571Z",
     "start_time": "2024-10-11T10:32:06.246090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Conv1D, LeakyReLU, Flatten, Dense, Concatenate\n",
    "from tensorflow.python.keras import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "model_input_lengths = {\n",
    "    'structure': 128,\n",
    "    'pattern': 256,\n",
    "    'trigger': 256,\n",
    "    'double': 256,\n",
    "}\n",
    "\n",
    "\n",
    "def create_cnn_lstm(input_shape, name_prefix):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN Layer with ReLU activation\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(input_layer)\n",
    "    conv = LeakyReLU()(conv)\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU()(conv)\n",
    "\n",
    "    # Flatten the CNN output\n",
    "    flatten = Flatten()(conv)\n",
    "\n",
    "    # LSTM Layer (LSTM has built-in activations)\n",
    "    lstm = LSTM(64, return_sequences=False)(tf.expand_dims(flatten, axis=1))\n",
    "\n",
    "    # Fully connected layer with ReLU activation\n",
    "    dense = Dense(64)(lstm)\n",
    "    dense = LeakyReLU()(dense)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=dense)\n",
    "\n",
    "\n",
    "def build_model(input_shapes):\n",
    "    structure_model = create_cnn_lstm((model_input_lengths['structure'], 5), 'structure_model')\n",
    "    pattern_model = create_cnn_lstm((model_input_lengths['pattern'], 5), 'pattern_model')\n",
    "    trigger_model = create_cnn_lstm((model_input_lengths['trigger'], 5), 'trigger_model')\n",
    "    double_model = create_cnn_lstm((model_input_lengths['double'], 5), 'double_model')\n",
    "\n",
    "    combined_output = Concatenate()(\n",
    "        [structure_model.output, pattern_model.output, trigger_model.output, double_model.output])\n",
    "\n",
    "    # Add an additional Dense layer with ReLU activation\n",
    "    combined_dense = Dense(128)(combined_output)\n",
    "    combined_dense = LeakyReLU()(combined_dense)\n",
    "\n",
    "    # Final output layer (for regression tasks, use linear activation; for classification, consider sigmoid/softmax)\n",
    "    final_output = Dense(1, activation='linear')(combined_dense)\n",
    "\n",
    "    # Define the final model\n",
    "    model = Model(inputs=[structure_model.input, pattern_model.input, trigger_model.input, double_model.input],\n",
    "                  outputs=final_output)\n",
    "\n",
    "    # Compile the model with mean squared error loss for regression tasks\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n"
   ],
   "id": "a1f1715472a3fc2b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check if model is not trained yet, try loading it from 'cnn_lstm_model.h5'. \n",
    "If it is already partially trained, or loaded from disk, continue training.\n",
    "after completing training on each set of data save model into 'cnn_lstm_model.h5' to prevent loosing data in case of computer restart.\n"
   ],
   "id": "8ce4bfcdb05bde50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:32:27.476008Z",
     "start_time": "2024-10-11T10:32:27.407896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "\n",
    "def train_model(structure_data, pattern_data, trigger_data, double_data, target_data, input_shapes, model=None):\n",
    "    '''\n",
    "    Check if the model is already trained or partially trained. If not, build a new model. \n",
    "    Continue training the model and save the trained model to 'cnn_lstm_model.h5' after each session.\n",
    "\n",
    "    Args:\n",
    "        structure_data: Data for the structure timeframe.\n",
    "        pattern_data: Data for the pattern timeframe.\n",
    "        trigger_data: Data for the trigger timeframe.\n",
    "        double_data: Data for the double timeframe.\n",
    "        target_data: The labels or target values for training.\n",
    "        input_shapes: A dictionary containing the input shapes for structure, pattern, trigger, and double timeframe data.\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    '''\n",
    "    # Check if the model already exists, load if it does\n",
    "    model_path = 'cnn_lstm_model.h5'\n",
    "\n",
    "    if model is None:\n",
    "        if os.path.exists(model_path):\n",
    "            print(\"Loading existing model from disk...\")\n",
    "            model = load_model(model_path)\n",
    "        else:\n",
    "            print(\"Building new model...\")\n",
    "            model = build_model(input_shapes)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([structure_data, pattern_data, trigger_data, double_data],\n",
    "                        target_data,\n",
    "                        epochs=10,\n",
    "                        batch_size=32)\n",
    "    print(history)\n",
    "    # Save the model after each training session to avoid losing progress\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved to disk.\")\n",
    "\n",
    "    return model"
   ],
   "id": "f9347e97cfa1de0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:32:27.988986Z",
     "start_time": "2024-10-11T10:32:27.555951Z"
    }
   },
   "cell_type": "code",
   "source": "n_mt_ohlcv.index.names",
   "id": "47019696734b90b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenList([None])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:32:37.704437Z",
     "start_time": "2024-10-11T10:32:28.125898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from helper.data_preparation import pattern_timeframe, trigger_timeframe\n",
    "from helper.importer import pt\n",
    "\n",
    "\n",
    "def prepare_train_n_test(t_structure_timeframe, mt_ohlcv: pt.DataFrame[MultiTimeframeOHLCV], forecast_horizon: int = 20,\n",
    "                         batch_size: int = 1000):\n",
    "    \"\"\"\n",
    "    Prepares input and output data for multi-step forecasting.\n",
    "    \n",
    "    Args:\n",
    "        mt_ohlcv: \n",
    "        t_structure_timeframe: \n",
    "        df (pd.DataFrame): DataFrame containing 'high' and 'low' columns.\n",
    "        window_size (int): Number of past time steps to use as input.\n",
    "        forecast_horizon (int): Number of future time steps to predict.\n",
    "        \n",
    "    Returns:\n",
    "        X (np.array): Input features.\n",
    "        y (np.array): Output targets (high and low).\n",
    "    \"\"\"\n",
    "    pattern_tf = pattern_timeframe(t_structure_timeframe)\n",
    "    trigger_tf = trigger_timeframe(t_structure_timeframe)\n",
    "    double_tf = pattern_timeframe(trigger_timeframe(t_structure_timeframe))\n",
    "\n",
    "    structure_df = single_timeframe(mt_ohlcv, t_structure_timeframe)\n",
    "    pattern_df = single_timeframe(mt_ohlcv, pattern_tf)\n",
    "    trigger_df = single_timeframe(mt_ohlcv, trigger_tf)\n",
    "    double_df = single_timeframe(mt_ohlcv, double_tf)\n",
    "\n",
    "    length_of_training = (\n",
    "            model_input_lengths['structure'] * pd.to_timedelta(t_structure_timeframe)\n",
    "            + model_input_lengths['pattern'] * pd.to_timedelta(pattern_tf)\n",
    "            + model_input_lengths['trigger'] * pd.to_timedelta(trigger_tf)\n",
    "            + model_input_lengths['double'] * pd.to_timedelta(double_tf)\n",
    "    )\n",
    "\n",
    "    input_start = mt_ohlcv.index.get_level_values(\n",
    "        level='date').min() + length_of_training * 2  # * 2 for simple safeside.\n",
    "    input_end = mt_ohlcv.index.get_level_values(level='date').max() - forecast_horizon * pd.to_timedelta(\n",
    "        trigger_tf)\n",
    "    duration_seconds = (input_end - input_start) / timedelta(seconds=1)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for relative_double_end in np.random.randint(0, duration_seconds, size=batch_size):\n",
    "        double_end = input_end - relative_double_end * timedelta(seconds=1)\n",
    "        trigger_end = double_end - model_input_lengths['double'] * pd.to_timedelta(double_tf)\n",
    "        pattern_end = trigger_end - model_input_lengths['trigger'] * pd.to_timedelta(double_tf)\n",
    "        structure_end = pattern_end - model_input_lengths['pattern'] * pd.to_timedelta(double_tf)\n",
    "\n",
    "        double_slice = structure_df.loc[(slice(None), slice(None, double_end)), :] \\\n",
    "                           .iloc[:-model_input_lengths['double']]\n",
    "        trigger_slice = pattern_df.loc[(slice(None), slice(None, trigger_end)), :] \\\n",
    "                            .iloc[:-model_input_lengths['trigger']]\n",
    "        pattern_slice = trigger_df.loc[(slice(None), slice(None, pattern_end)), :] \\\n",
    "                            .iloc[:-model_input_lengths['pattern']]\n",
    "        structure_slice = double_df.loc[(slice(None), slice(None, structure_end)), :] \\\n",
    "                              .iloc[:-model_input_lengths['structure']]\n",
    "\n",
    "        X['double'].append(double_slice)\n",
    "        X['trigger'].append(trigger_slice)\n",
    "        X['pattern'].append(pattern_slice)\n",
    "        X['structure'].append(structure_slice)\n",
    "\n",
    "        future_slice = trigger_df.loc[(slice(None), slice(pattern_end, None)), :] \\\n",
    "                           .iloc[:-model_input_lengths['pattern']]\n",
    "        y.append(future_slice)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "a = prepare_train_n_test('4h', n_mt_ohlcv, 10)\n",
    "a"
   ],
   "id": "c4fda4bf2a9b30c7",
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "multi_timeframe_data expected to have \"timeframe\" in indexes:[[None]]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 74\u001B[0m\n\u001B[0;32m     70\u001B[0m         y\u001B[38;5;241m.\u001B[39mappend(future_slice)\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(X), np\u001B[38;5;241m.\u001B[39marray(y)\n\u001B[1;32m---> 74\u001B[0m a \u001B[38;5;241m=\u001B[39m prepare_train_n_test(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m4h\u001B[39m\u001B[38;5;124m'\u001B[39m, n_mt_ohlcv, \u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m     75\u001B[0m a\n",
      "Cell \u001B[1;32mIn[6], line 27\u001B[0m, in \u001B[0;36mprepare_train_n_test\u001B[1;34m(t_structure_timeframe, mt_ohlcv, forecast_horizon, batch_size)\u001B[0m\n\u001B[0;32m     24\u001B[0m trigger_tf \u001B[38;5;241m=\u001B[39m trigger_timeframe(t_structure_timeframe)\n\u001B[0;32m     25\u001B[0m double_tf \u001B[38;5;241m=\u001B[39m pattern_timeframe(trigger_timeframe(t_structure_timeframe))\n\u001B[1;32m---> 27\u001B[0m structure_df \u001B[38;5;241m=\u001B[39m single_timeframe(mt_ohlcv, t_structure_timeframe)\n\u001B[0;32m     28\u001B[0m pattern_df \u001B[38;5;241m=\u001B[39m single_timeframe(mt_ohlcv, pattern_tf)\n\u001B[0;32m     29\u001B[0m trigger_df \u001B[38;5;241m=\u001B[39m single_timeframe(mt_ohlcv, trigger_tf)\n",
      "File \u001B[1;32mC:\\Code\\dl-forcasting\\src\\helper\\data_preparation.py:317\u001B[0m, in \u001B[0;36msingle_timeframe\u001B[1;34m(multi_timeframe_data, timeframe, keep_timeframe, sort, index_only)\u001B[0m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msingle_timeframe\u001B[39m(multi_timeframe_data: pt\u001B[38;5;241m.\u001B[39mDataFrame[MultiTimeframe_Type], timeframe, keep_timeframe: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    314\u001B[0m                      sort:\u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, index_only: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)\\\n\u001B[0;32m    315\u001B[0m         \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeframe\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m multi_timeframe_data\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mnames:\n\u001B[1;32m--> 317\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[0;32m    318\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmulti_timeframe_data expected to have \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeframe\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m in indexes:[\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmulti_timeframe_data\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mnames\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeframe \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m config\u001B[38;5;241m.\u001B[39mtimeframes:\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[0;32m    321\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeframe:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtimeframe\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not in supported timeframes:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39mtimeframes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mException\u001B[0m: multi_timeframe_data expected to have \"timeframe\" in indexes:[[None]]"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "structure_timeframes = {\n",
    "    '1W': {'pattern': '1D', 'trigger': '4h', 'double': '15min'},\n",
    "    '1D': {'pattern': '4h', 'trigger': '1h', 'double': '5min'},\n",
    "    '4h': {'pattern': '1h', 'trigger': '15min', 'double': '1min'}\n",
    "}\n",
    "loop over structure timeframe in ['1D', '4h']:\n",
    "collect information from already prepared function read_ohlcv_features(start, end, timeframe)\n",
    "create required iteration to pass data to train_model\n",
    "choose double_timeframe_end in the range of start and end\n",
    "structure_timeframe_end= structure_timeframe_end = trigger_timeframe_end = double_timeframe_end\n",
    "calculate trigger_timeframe_start according to trigger_timeframe_end and number of bars shall be passed for taining 'trigger_model' \n",
    "calculate pattern_timeframe_start according to pattern_timeframe_end and number of bars shall be passed for taining 'pattern_model' \n",
    "calculate structure_timeframe_start according to structure_timeframe_end and number of bars shall be passed for taining 'structure_model' \n",
    "\n",
    "for:\n",
    "```python\n",
    "def create_cnn_lstm(input_shape, name_prefix):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN Layer with ReLU activation\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(input_layer)\n",
    "    conv = LeakyReLU()(conv)\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU()(conv)\n",
    "\n",
    "    # Flatten the CNN output\n",
    "    flatten = Flatten()(conv)\n",
    "\n",
    "    # LSTM Layer (LSTM has built-in activations)\n",
    "    lstm = LSTM(64, return_sequences=False)(tf.expand_dims(flatten, axis=1))\n",
    "\n",
    "    # Fully connected layer with ReLU activation\n",
    "    dense = Dense(64)(lstm)\n",
    "    dense = LeakyReLU()(dense)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=dense)\n",
    "\n",
    "def build_model(input_shapes):\n",
    "    structure_model = create_cnn_lstm((128, 5), 'structure_model')\n",
    "    pattern_model = create_cnn_lstm((256, 5), 'pattern_model')\n",
    "    trigger_model = create_cnn_lstm((256, 5), 'trigger_model')\n",
    "    double_model = create_cnn_lstm((256, 5), 'double_model')\n",
    "    \n",
    "    combined_output = Concatenate()(\n",
    "        [structure_model.output, pattern_model.output, trigger_model.output, double_model.output])\n",
    "    \n",
    "    # Add an additional Dense layer with ReLU activation\n",
    "    combined_dense = Dense(128)(combined_output)\n",
    "    combined_dense = LeakyReLU()(combined_dense)\n",
    "    \n",
    "    # Final output layer (for regression tasks, use linear activation; for classification, consider sigmoid/softmax)\n",
    "    final_output = Dense(1, activation='linear')(combined_dense)\n",
    "    \n",
    "    # Define the final model\n",
    "    model = Model(inputs=[structure_model.input, pattern_model.input, trigger_model.input, double_model.input],\n",
    "                  outputs=final_output)\n",
    "    \n",
    "    # Compile the model with mean squared error loss for regression tasks\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "def train_model(structure_data, pattern_data, trigger_data, double_data, target_data, input_shapes, model = None):\n",
    "    '''\n",
    "    Check if the model is already trained or partially trained. If not, build a new model. \n",
    "    Continue training the model and save the trained model to 'cnn_lstm_model.h5' after each session.\n",
    "\n",
    "    Args:\n",
    "        structure_data: Data for the structure timeframe.\n",
    "        pattern_data: Data for the pattern timeframe.\n",
    "        trigger_data: Data for the trigger timeframe.\n",
    "        double_data: Data for the double timeframe.\n",
    "        target_data: The labels or target values for training.\n",
    "        input_shapes: A dictionary containing the input shapes for structure, pattern, trigger, and double timeframe data.\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    '''\n",
    "    # Check if the model already exists, load if it does\n",
    "    model_path = 'cnn_lstm_model.h5'\n",
    "    \n",
    "    if model is None:\n",
    "        if os.path.exists(model_path):\n",
    "            print(\"Loading existing model from disk...\")\n",
    "            model = load_model(model_path)\n",
    "        else:\n",
    "            print(\"Building new model...\")\n",
    "            model = build_model(input_shapes)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([structure_data, pattern_data, trigger_data, double_data],\n",
    "                        target_data,\n",
    "                        epochs=10,\n",
    "                        batch_size=32)\n",
    "    print(history)\n",
    "    # Save the model after each training session to avoid losing progress\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved to disk.\")\n",
    "    \n",
    "    return model\n",
    "```"
   ],
   "id": "8976c18cf541c107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "22c671f910aa6071"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "structure_timeframes = {\n",
    "    '1W': {'pattern': '1D', 'trigger': '4h', 'double': '15min'},\n",
    "    '1D': {'pattern': '4h', 'trigger': '1h', 'double': '5min'},\n",
    "    '4h': {'pattern': '1h', 'trigger': '15min', 'double': '1min'}\n",
    "}\n",
    "\n",
    "\n",
    "def "
   ],
   "id": "96dace33290dc1cf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
