{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T10:58:02.017386Z",
     "start_time": "2024-09-27T10:57:48.986391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "from helper.helper import date_range_to_string\n",
    "from Config import config\n",
    "\n",
    "config.processing_date_range = date_range_to_string(start=pd.to_datetime('03-01-24'),\n",
    "                                                    end=pd.to_datetime('09-01-24'))\n",
    "n_mt_ohlcv = pd.read_csv(\n",
    "    os.path.join(r\"C:\\Code\\dl-forcasting\\data\",\n",
    "                 f\"n_mt_ohlcv.{config.processing_date_range}.csv.zip\"), compression='zip')\n",
    "n_mt_ohlcv"
   ],
   "id": "9caca9023e737e7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mDEBUG@\u001B[94m09-27.14:27:56:\u001B[92m...Starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       timeframe                       date      open     close      high  \\\n",
       "0          15min  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "1             1D  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "2             1h  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "3           1min  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "4             4h  2024-03-01 00:00:00+00:00       NaN       NaN       NaN   \n",
       "...          ...                        ...       ...       ...       ...   \n",
       "341347        1D  2024-09-01 00:00:00+00:00 -0.684385 -1.265078 -1.114403   \n",
       "341348        1h  2024-09-01 00:00:00+00:00 -0.081138 -0.165222 -0.038223   \n",
       "341349      1min  2024-09-01 00:00:00+00:00 -0.018025 -0.275889 -0.122945   \n",
       "341350        4h  2024-09-01 00:00:00+00:00 -0.116954 -0.577484 -0.395726   \n",
       "341351      5min  2024-09-01 00:00:00+00:00  0.019726  0.277921  0.054425   \n",
       "\n",
       "             low    volume  \n",
       "0            NaN       NaN  \n",
       "1            NaN       NaN  \n",
       "2            NaN       NaN  \n",
       "3            NaN       NaN  \n",
       "4            NaN       NaN  \n",
       "...          ...       ...  \n",
       "341347 -0.900461  0.298451  \n",
       "341348 -0.001254 -0.095335  \n",
       "341349 -0.169871 -0.171993  \n",
       "341350 -0.480249  0.044290  \n",
       "341351  0.034553 -0.011040  \n",
       "\n",
       "[341352 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeframe</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15min</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1D</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1h</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1min</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4h</td>\n",
       "      <td>2024-03-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341347</th>\n",
       "      <td>1D</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>-0.684385</td>\n",
       "      <td>-1.265078</td>\n",
       "      <td>-1.114403</td>\n",
       "      <td>-0.900461</td>\n",
       "      <td>0.298451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341348</th>\n",
       "      <td>1h</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>-0.081138</td>\n",
       "      <td>-0.165222</td>\n",
       "      <td>-0.038223</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>-0.095335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341349</th>\n",
       "      <td>1min</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>-0.018025</td>\n",
       "      <td>-0.275889</td>\n",
       "      <td>-0.122945</td>\n",
       "      <td>-0.169871</td>\n",
       "      <td>-0.171993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341350</th>\n",
       "      <td>4h</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>-0.116954</td>\n",
       "      <td>-0.577484</td>\n",
       "      <td>-0.395726</td>\n",
       "      <td>-0.480249</td>\n",
       "      <td>0.044290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341351</th>\n",
       "      <td>5min</td>\n",
       "      <td>2024-09-01 00:00:00+00:00</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>0.277921</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.034553</td>\n",
       "      <td>-0.011040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341352 rows Ã— 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T10:58:03.126442Z",
     "start_time": "2024-09-27T10:58:02.272781Z"
    }
   },
   "cell_type": "code",
   "source": "n_mt_ohlcv.describe()",
   "id": "db6e26c4e54b9820",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                open          close           high            low  \\\n",
       "count  340668.000000  340668.000000  340668.000000  340668.000000   \n",
       "mean        0.002571       0.002537       0.000586       0.004814   \n",
       "std         1.080184       1.080047       1.081013       1.083676   \n",
       "min       -11.829250     -11.796538     -10.789105     -12.271370   \n",
       "25%        -0.556785      -0.557024      -0.575532      -0.531490   \n",
       "50%         0.010991       0.010835      -0.014932       0.036296   \n",
       "75%         0.575594       0.574331       0.553501       0.591531   \n",
       "max        13.730087      13.773854      13.686195      12.303279   \n",
       "\n",
       "              volume  \n",
       "count  340668.000000  \n",
       "mean        0.011528  \n",
       "std         1.070377  \n",
       "min        -4.911268  \n",
       "25%        -0.405402  \n",
       "50%        -0.136793  \n",
       "75%         0.143095  \n",
       "max        15.969589  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>0.011528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.080184</td>\n",
       "      <td>1.080047</td>\n",
       "      <td>1.081013</td>\n",
       "      <td>1.083676</td>\n",
       "      <td>1.070377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-11.829250</td>\n",
       "      <td>-11.796538</td>\n",
       "      <td>-10.789105</td>\n",
       "      <td>-12.271370</td>\n",
       "      <td>-4.911268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.556785</td>\n",
       "      <td>-0.557024</td>\n",
       "      <td>-0.575532</td>\n",
       "      <td>-0.531490</td>\n",
       "      <td>-0.405402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>-0.014932</td>\n",
       "      <td>0.036296</td>\n",
       "      <td>-0.136793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.575594</td>\n",
       "      <td>0.574331</td>\n",
       "      <td>0.553501</td>\n",
       "      <td>0.591531</td>\n",
       "      <td>0.143095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.730087</td>\n",
       "      <td>13.773854</td>\n",
       "      <td>13.686195</td>\n",
       "      <td>12.303279</td>\n",
       "      <td>15.969589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multi timeframe modelling\n",
    "\n",
    "\n",
    "structure_timeframes = {\n",
    "    '1W':{        pattern: '1D',        trigger: '4h',        double: '15min',    }, \n",
    "    '1D':{        pattern: '4h',        trigger: '1h',        double: '5min',    }, \n",
    "    '4h':{        pattern: '1h',        trigger: '15min',        double: '1min',    }, \n",
    "}\n",
    "n_mt_ohlcv include open, high, low, close, and volume of all timeframes.\n",
    "single_timeframe(n_mt_ohlcv, timeframe) will return data of specified timeframe.\n",
    "using tensorflow create 4 parallel CNN-LSTM models each fed with structure, pattern, trigger, and double timeframe data.\n",
    "join these parallel models together.\n"
   ],
   "id": "6427f865497c1ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T11:26:53.421274Z",
     "start_time": "2024-09-27T11:26:52.115356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.python.keras import Input, Model\n",
    "from tensorflow.python.keras.layers import Conv1D, LeakyReLU, Flatten, LSTM, Dense, Concatenate\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_cnn_lstm(input_shape, name_prefix):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN Layer with ReLU activation\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(input_layer)\n",
    "    conv = LeakyReLU()(conv)\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU()(conv)\n",
    "\n",
    "    # Flatten the CNN output\n",
    "    flatten = Flatten()(conv)\n",
    "\n",
    "    # LSTM Layer (LSTM has built-in activations)\n",
    "    lstm = LSTM(64, return_sequences=False)(tf.expand_dims(flatten, axis=1))\n",
    "\n",
    "    # Fully connected layer with ReLU activation\n",
    "    dense = Dense(64)(lstm)\n",
    "    dense = LeakyReLU()(dense)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=dense)\n",
    "\n",
    "def build_model(input_shapes):\n",
    "    structure_model = create_cnn_lstm((128, 5), 'structure_model')\n",
    "    pattern_model = create_cnn_lstm((256, 5), 'pattern_model')\n",
    "    trigger_model = create_cnn_lstm((256, 5), 'trigger_model')\n",
    "    double_model = create_cnn_lstm((256, 5), 'double_model')\n",
    "    \n",
    "    combined_output = Concatenate()(\n",
    "        [structure_model.output, pattern_model.output, trigger_model.output, double_model.output])\n",
    "    \n",
    "    # Add an additional Dense layer with ReLU activation\n",
    "    combined_dense = Dense(128)(combined_output)\n",
    "    combined_dense = LeakyReLU()(combined_dense)\n",
    "    \n",
    "    # Final output layer (for regression tasks, use linear activation; for classification, consider sigmoid/softmax)\n",
    "    final_output = Dense(1, activation='linear')(combined_dense)\n",
    "    \n",
    "    # Define the final model\n",
    "    model = Model(inputs=[structure_model.input, pattern_model.input, trigger_model.input, double_model.input],\n",
    "                  outputs=final_output)\n",
    "    \n",
    "    # Compile the model with mean squared error loss for regression tasks\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n"
   ],
   "id": "a1f1715472a3fc2b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 22\u001B[0m\n\u001B[0;32m     18\u001B[0m     dense \u001B[38;5;241m=\u001B[39m LeakyReLU()(dense)\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Model(inputs\u001B[38;5;241m=\u001B[39minput_layer, outputs\u001B[38;5;241m=\u001B[39mdense)\n\u001B[1;32m---> 22\u001B[0m structure_model \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_cnn_lstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstructure_model\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m pattern_model \u001B[38;5;241m=\u001B[39m create_cnn_lstm((\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m5\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpattern_model\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     24\u001B[0m trigger_model \u001B[38;5;241m=\u001B[39m create_cnn_lstm((\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m5\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrigger_model\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m, in \u001B[0;36mcreate_cnn_lstm\u001B[1;34m(input_shape, name_prefix)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_cnn_lstm\u001B[39m(input_shape, name_prefix):\n\u001B[1;32m----> 2\u001B[0m     input_layer \u001B[38;5;241m=\u001B[39m \u001B[43mInput\u001B[49m(shape\u001B[38;5;241m=\u001B[39minput_shape)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# CNN Layer with ReLU activation\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     conv \u001B[38;5;241m=\u001B[39m Conv1D(filters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m'\u001B[39m)(input_layer)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Input' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check if model is not trained yet, try loading it from 'cnn_lstm_model.h5'. \n",
    "If it is already partially trained, or loaded from disk, continue training.\n",
    "after completing training on each set of data save model into 'cnn_lstm_model.h5' to prevent loosing data in case of computer restart.\n"
   ],
   "id": "8ce4bfcdb05bde50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "def train_model(structure_data, pattern_data, trigger_data, double_data, target_data, input_shapes, model = None):\n",
    "    '''\n",
    "    Check if the model is already trained or partially trained. If not, build a new model. \n",
    "    Continue training the model and save the trained model to 'cnn_lstm_model.h5' after each session.\n",
    "\n",
    "    Args:\n",
    "        structure_data: Data for the structure timeframe.\n",
    "        pattern_data: Data for the pattern timeframe.\n",
    "        trigger_data: Data for the trigger timeframe.\n",
    "        double_data: Data for the double timeframe.\n",
    "        target_data: The labels or target values for training.\n",
    "        input_shapes: A dictionary containing the input shapes for structure, pattern, trigger, and double timeframe data.\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    '''\n",
    "    # Check if the model already exists, load if it does\n",
    "    model_path = 'cnn_lstm_model.h5'\n",
    "    \n",
    "    if model is None:\n",
    "        if os.path.exists(model_path):\n",
    "            print(\"Loading existing model from disk...\")\n",
    "            model = load_model(model_path)\n",
    "        else:\n",
    "            print(\"Building new model...\")\n",
    "            model = build_model(input_shapes)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([structure_data, pattern_data, trigger_data, double_data],\n",
    "                        target_data,\n",
    "                        epochs=10,\n",
    "                        batch_size=32)\n",
    "    print(history)\n",
    "    # Save the model after each training session to avoid losing progress\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved to disk.\")\n",
    "    \n",
    "    return model"
   ],
   "id": "f9347e97cfa1de0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "structure_timeframes = {\n",
    "    '1W': {'pattern': '1D', 'trigger': '4h', 'double': '15min'},\n",
    "    '1D': {'pattern': '4h', 'trigger': '1h', 'double': '5min'},\n",
    "    '4h': {'pattern': '1h', 'trigger': '15min', 'double': '1min'}\n",
    "}\n",
    "loop over structure timeframe in ['1D', '4h']:\n",
    "collect information from already prepared function read_ohlcv_features(start, end, timeframe)\n",
    "create required iteration to pass data to train_model\n",
    "choose double_timeframe_end in the range of start and end\n",
    "structure_timeframe_end= structure_timeframe_end = trigger_timeframe_end = double_timeframe_end\n",
    "calculate trigger_timeframe_start according to trigger_timeframe_end and number of bars shall be passed for taining 'trigger_model' \n",
    "calculate pattern_timeframe_start according to pattern_timeframe_end and number of bars shall be passed for taining 'pattern_model' \n",
    "calculate structure_timeframe_start according to structure_timeframe_end and number of bars shall be passed for taining 'structure_model' \n",
    "\n",
    "for:\n",
    "```python\n",
    "def create_cnn_lstm(input_shape, name_prefix):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN Layer with ReLU activation\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(input_layer)\n",
    "    conv = LeakyReLU()(conv)\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU()(conv)\n",
    "\n",
    "    # Flatten the CNN output\n",
    "    flatten = Flatten()(conv)\n",
    "\n",
    "    # LSTM Layer (LSTM has built-in activations)\n",
    "    lstm = LSTM(64, return_sequences=False)(tf.expand_dims(flatten, axis=1))\n",
    "\n",
    "    # Fully connected layer with ReLU activation\n",
    "    dense = Dense(64)(lstm)\n",
    "    dense = LeakyReLU()(dense)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=dense)\n",
    "\n",
    "def build_model(input_shapes):\n",
    "    structure_model = create_cnn_lstm((128, 5), 'structure_model')\n",
    "    pattern_model = create_cnn_lstm((256, 5), 'pattern_model')\n",
    "    trigger_model = create_cnn_lstm((256, 5), 'trigger_model')\n",
    "    double_model = create_cnn_lstm((256, 5), 'double_model')\n",
    "    \n",
    "    combined_output = Concatenate()(\n",
    "        [structure_model.output, pattern_model.output, trigger_model.output, double_model.output])\n",
    "    \n",
    "    # Add an additional Dense layer with ReLU activation\n",
    "    combined_dense = Dense(128)(combined_output)\n",
    "    combined_dense = LeakyReLU()(combined_dense)\n",
    "    \n",
    "    # Final output layer (for regression tasks, use linear activation; for classification, consider sigmoid/softmax)\n",
    "    final_output = Dense(1, activation='linear')(combined_dense)\n",
    "    \n",
    "    # Define the final model\n",
    "    model = Model(inputs=[structure_model.input, pattern_model.input, trigger_model.input, double_model.input],\n",
    "                  outputs=final_output)\n",
    "    \n",
    "    # Compile the model with mean squared error loss for regression tasks\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "def train_model(structure_data, pattern_data, trigger_data, double_data, target_data, input_shapes, model = None):\n",
    "    '''\n",
    "    Check if the model is already trained or partially trained. If not, build a new model. \n",
    "    Continue training the model and save the trained model to 'cnn_lstm_model.h5' after each session.\n",
    "\n",
    "    Args:\n",
    "        structure_data: Data for the structure timeframe.\n",
    "        pattern_data: Data for the pattern timeframe.\n",
    "        trigger_data: Data for the trigger timeframe.\n",
    "        double_data: Data for the double timeframe.\n",
    "        target_data: The labels or target values for training.\n",
    "        input_shapes: A dictionary containing the input shapes for structure, pattern, trigger, and double timeframe data.\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    '''\n",
    "    # Check if the model already exists, load if it does\n",
    "    model_path = 'cnn_lstm_model.h5'\n",
    "    \n",
    "    if model is None:\n",
    "        if os.path.exists(model_path):\n",
    "            print(\"Loading existing model from disk...\")\n",
    "            model = load_model(model_path)\n",
    "        else:\n",
    "            print(\"Building new model...\")\n",
    "            model = build_model(input_shapes)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([structure_data, pattern_data, trigger_data, double_data],\n",
    "                        target_data,\n",
    "                        epochs=10,\n",
    "                        batch_size=32)\n",
    "    print(history)\n",
    "    # Save the model after each training session to avoid losing progress\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved to disk.\")\n",
    "    \n",
    "    return model\n",
    "```"
   ],
   "id": "8976c18cf541c107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "22c671f910aa6071"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "structure_timeframes = {\n",
    "    '1W': {'pattern': '1D', 'trigger': '4h', 'double': '15min'},\n",
    "    '1D': {'pattern': '4h', 'trigger': '1h', 'double': '5min'},\n",
    "    '4h': {'pattern': '1h', 'trigger': '15min', 'double': '1min'}\n",
    "}\n",
    "def "
   ],
   "id": "96dace33290dc1cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
