{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PanderaDFM.OHLCV import MultiTimeframeOHLCV\n",
    "from helper.data_preparation import single_timeframe\n",
    "from helper.helper import date_range_to_string\n",
    "from Config import config\n",
    "\n",
    "config.processing_date_range = date_range_to_string(start=pd.to_datetime('03-01-24'),\n",
    "                                                    end=pd.to_datetime('09-01-24'))\n",
    "# devided by rolling mean, std\n",
    "n_mt_ohlcv = pd.read_csv(\n",
    "    os.path.join(r\"C:\\Code\\dl-forcasting\\data\",\n",
    "                 f\"n_mt_ohlcv.{config.processing_date_range}.csv.zip\"), compression='zip')\n",
    "n_mt_ohlcv"
   ],
   "id": "9caca9023e737e7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "n_mt_ohlcv.describe()",
   "id": "db6e26c4e54b9820",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multi timeframe modelling\n",
    "\n",
    "\n",
    "structure_timeframes = {\n",
    "    '1W':{        pattern: '1D',        trigger: '4h',        double: '15min',    }, \n",
    "    '1D':{        pattern: '4h',        trigger: '1h',        double: '5min',    }, \n",
    "    '4h':{        pattern: '1h',        trigger: '15min',        double: '1min',    }, \n",
    "}\n",
    "n_mt_ohlcv include open, high, low, close, and volume of all timeframes.\n",
    "single_timeframe(n_mt_ohlcv, timeframe) will return data of specified timeframe.\n",
    "using tensorflow create 4 parallel CNN-LSTM models each fed with structure, pattern, trigger, and double timeframe data.\n",
    "join these parallel models together.\n"
   ],
   "id": "6427f865497c1ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.python.keras import Input, Model\n",
    "from tensorflow.python.keras.layers import Conv1D, LeakyReLU, Flatten, LSTM, Dense, Concatenate\n",
    "import tensorflow as tf\n",
    "\n",
    "model_input_lengths = {\n",
    "    'structure': 128,\n",
    "    'pattern': 256,\n",
    "    'trigger': 256,\n",
    "    'double': 256,\n",
    "}\n",
    "\n",
    "\n",
    "def create_cnn_lstm(input_shape, name_prefix):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN Layer with ReLU activation\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(input_layer)\n",
    "    conv = LeakyReLU()(conv)\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU()(conv)\n",
    "\n",
    "    # Flatten the CNN output\n",
    "    flatten = Flatten()(conv)\n",
    "\n",
    "    # LSTM Layer (LSTM has built-in activations)\n",
    "    lstm = LSTM(64, return_sequences=False)(tf.expand_dims(flatten, axis=1))\n",
    "\n",
    "    # Fully connected layer with ReLU activation\n",
    "    dense = Dense(64)(lstm)\n",
    "    dense = LeakyReLU()(dense)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=dense)\n",
    "\n",
    "\n",
    "def build_model(input_shapes):\n",
    "    structure_model = create_cnn_lstm((model_input_lengths['structure'], 5), 'structure_model')\n",
    "    pattern_model = create_cnn_lstm((model_input_lengths['pattern'], 5), 'pattern_model')\n",
    "    trigger_model = create_cnn_lstm((model_input_lengths['trigger'], 5), 'trigger_model')\n",
    "    double_model = create_cnn_lstm((model_input_lengths['double'], 5), 'double_model')\n",
    "\n",
    "    combined_output = Concatenate()(\n",
    "        [structure_model.output, pattern_model.output, trigger_model.output, double_model.output])\n",
    "\n",
    "    # Add an additional Dense layer with ReLU activation\n",
    "    combined_dense = Dense(128)(combined_output)\n",
    "    combined_dense = LeakyReLU()(combined_dense)\n",
    "\n",
    "    # Final output layer (for regression tasks, use linear activation; for classification, consider sigmoid/softmax)\n",
    "    final_output = Dense(1, activation='linear')(combined_dense)\n",
    "\n",
    "    # Define the final model\n",
    "    model = Model(inputs=[structure_model.input, pattern_model.input, trigger_model.input, double_model.input],\n",
    "                  outputs=final_output)\n",
    "\n",
    "    # Compile the model with mean squared error loss for regression tasks\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n"
   ],
   "id": "a1f1715472a3fc2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check if model is not trained yet, try loading it from 'cnn_lstm_model.h5'. \n",
    "If it is already partially trained, or loaded from disk, continue training.\n",
    "after completing training on each set of data save model into 'cnn_lstm_model.h5' to prevent loosing data in case of computer restart.\n"
   ],
   "id": "8ce4bfcdb05bde50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "\n",
    "def train_model(structure_data, pattern_data, trigger_data, double_data, target_data, input_shapes, model=None):\n",
    "    '''\n",
    "    Check if the model is already trained or partially trained. If not, build a new model. \n",
    "    Continue training the model and save the trained model to 'cnn_lstm_model.h5' after each session.\n",
    "\n",
    "    Args:\n",
    "        structure_data: Data for the structure timeframe.\n",
    "        pattern_data: Data for the pattern timeframe.\n",
    "        trigger_data: Data for the trigger timeframe.\n",
    "        double_data: Data for the double timeframe.\n",
    "        target_data: The labels or target values for training.\n",
    "        input_shapes: A dictionary containing the input shapes for structure, pattern, trigger, and double timeframe data.\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    '''\n",
    "    # Check if the model already exists, load if it does\n",
    "    model_path = 'cnn_lstm_model.h5'\n",
    "\n",
    "    if model is None:\n",
    "        if os.path.exists(model_path):\n",
    "            print(\"Loading existing model from disk...\")\n",
    "            model = load_model(model_path)\n",
    "        else:\n",
    "            print(\"Building new model...\")\n",
    "            model = build_model(input_shapes)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([structure_data, pattern_data, trigger_data, double_data],\n",
    "                        target_data,\n",
    "                        epochs=10,\n",
    "                        batch_size=32)\n",
    "    print(history)\n",
    "    # Save the model after each training session to avoid losing progress\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved to disk.\")\n",
    "\n",
    "    return model"
   ],
   "id": "f9347e97cfa1de0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from helper.data_preparation import pattern_timeframe, trigger_timeframe\n",
    "from helper.importer import pt\n",
    "\n",
    "\n",
    "def prepare_data(t_structure_timeframe, mt_ohlcv: pt.DataFrame[MultiTimeframeOHLCV], forecast_horizon=20,\n",
    "                 batch_size: int = 1000):\n",
    "    \"\"\"\n",
    "    Prepares input and output data for multi-step forecasting.\n",
    "    \n",
    "    Args:\n",
    "        mt_ohlcv: \n",
    "        t_structure_timeframe: \n",
    "        df (pd.DataFrame): DataFrame containing 'high' and 'low' columns.\n",
    "        window_size (int): Number of past time steps to use as input.\n",
    "        forecast_horizon (int): Number of future time steps to predict.\n",
    "        \n",
    "    Returns:\n",
    "        X (np.array): Input features.\n",
    "        y (np.array): Output targets (high and low).\n",
    "    \"\"\"\n",
    "    t_pattern_timeframe = pattern_timeframe(t_structure_timeframe)\n",
    "    t_trigger_timeframe = trigger_timeframe(t_structure_timeframe)\n",
    "    t_double_timeframe = pattern_timeframe(trigger_timeframe(t_structure_timeframe))\n",
    "\n",
    "    structure_df = single_timeframe(mt_ohlcv, t_structure_timeframe)\n",
    "    pattern_df = single_timeframe(mt_ohlcv, t_pattern_timeframe)\n",
    "    trigger_df = single_timeframe(mt_ohlcv, t_trigger_timeframe)\n",
    "    double_df = single_timeframe(mt_ohlcv, t_double_timeframe)\n",
    "\n",
    "    length_of_training = (\n",
    "            model_input_lengths['structure'] * pd.to_timedelta(t_structure_timeframe)\n",
    "            + model_input_lengths['pattern'] * pd.to_timedelta(t_pattern_timeframe)\n",
    "            + model_input_lengths['trigger'] * pd.to_timedelta(t_trigger_timeframe)\n",
    "            + model_input_lengths['double'] * pd.to_timedelta(t_double_timeframe)\n",
    "    )\n",
    "\n",
    "    input_start = mt_ohlcv.index.get_level_values(\n",
    "        level='date').min() + length_of_training * 2  # * 2 for simple safeside.\n",
    "    input_end = mt_ohlcv.index.get_level_values(level='date').max() - forecast_horizon * pd.to_timedelta(\n",
    "        t_trigger_timeframe)\n",
    "    duration_seconds = (input_end - input_start) / timedelta(seconds=1)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for relative_double_end in np.random.randint(0, duration_seconds, size=batch_size):\n",
    "        double_end = input_end - relative_double_end * timedelta(seconds=1)\n",
    "        trigger_end = double_end - model_input_lengths['double'] * pd.to_timedelta(t_double_timeframe)\n",
    "        pattern_end = trigger_end - model_input_lengths['trigger'] * pd.to_timedelta(t_double_timeframe)\n",
    "        structure_end = pattern_end - model_input_lengths['pattern'] * pd.to_timedelta(t_double_timeframe)\n",
    "\n",
    "        double_slice = structure_df.loc[(slice(None), slice(None, double_end)), :] \\\n",
    "                           .iloc[:-model_input_lengths['double']]\n",
    "        trigger_slice = pattern_df.loc[(slice(None), slice(None, trigger_end)), :] \\\n",
    "                            .iloc[:-model_input_lengths['trigger']]\n",
    "        pattern_slice = trigger_df.loc[(slice(None), slice(None, pattern_end)), :] \\\n",
    "                            .iloc[:-model_input_lengths['pattern']]\n",
    "        structure_slice = double_df.loc[(slice(None), slice(None, structure_end)), :] \\\n",
    "                              .iloc[:-model_input_lengths['structure']]\n",
    "\n",
    "        X['double'].append(double_slice)\n",
    "        X['trigger'].append(trigger_slice)\n",
    "        X['pattern'].append(pattern_slice)\n",
    "        X['structure'].append(structure_slice)\n",
    "\n",
    "        future_slice = trigger_df.loc[(slice(None), slice(pattern_end, None)), :] \\\n",
    "                           .iloc[:-model_input_lengths['pattern']]\n",
    "        y.append(future_slice)\n",
    "    return np.array(X), np.array(y)\n"
   ],
   "id": "c4fda4bf2a9b30c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "structure_timeframes = {\n",
    "    '1W': {'pattern': '1D', 'trigger': '4h', 'double': '15min'},\n",
    "    '1D': {'pattern': '4h', 'trigger': '1h', 'double': '5min'},\n",
    "    '4h': {'pattern': '1h', 'trigger': '15min', 'double': '1min'}\n",
    "}\n",
    "loop over structure timeframe in ['1D', '4h']:\n",
    "collect information from already prepared function read_ohlcv_features(start, end, timeframe)\n",
    "create required iteration to pass data to train_model\n",
    "choose double_timeframe_end in the range of start and end\n",
    "structure_timeframe_end= structure_timeframe_end = trigger_timeframe_end = double_timeframe_end\n",
    "calculate trigger_timeframe_start according to trigger_timeframe_end and number of bars shall be passed for taining 'trigger_model' \n",
    "calculate pattern_timeframe_start according to pattern_timeframe_end and number of bars shall be passed for taining 'pattern_model' \n",
    "calculate structure_timeframe_start according to structure_timeframe_end and number of bars shall be passed for taining 'structure_model' \n",
    "\n",
    "for:\n",
    "```python\n",
    "def create_cnn_lstm(input_shape, name_prefix):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN Layer with ReLU activation\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(input_layer)\n",
    "    conv = LeakyReLU()(conv)\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU()(conv)\n",
    "\n",
    "    # Flatten the CNN output\n",
    "    flatten = Flatten()(conv)\n",
    "\n",
    "    # LSTM Layer (LSTM has built-in activations)\n",
    "    lstm = LSTM(64, return_sequences=False)(tf.expand_dims(flatten, axis=1))\n",
    "\n",
    "    # Fully connected layer with ReLU activation\n",
    "    dense = Dense(64)(lstm)\n",
    "    dense = LeakyReLU()(dense)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=dense)\n",
    "\n",
    "def build_model(input_shapes):\n",
    "    structure_model = create_cnn_lstm((128, 5), 'structure_model')\n",
    "    pattern_model = create_cnn_lstm((256, 5), 'pattern_model')\n",
    "    trigger_model = create_cnn_lstm((256, 5), 'trigger_model')\n",
    "    double_model = create_cnn_lstm((256, 5), 'double_model')\n",
    "    \n",
    "    combined_output = Concatenate()(\n",
    "        [structure_model.output, pattern_model.output, trigger_model.output, double_model.output])\n",
    "    \n",
    "    # Add an additional Dense layer with ReLU activation\n",
    "    combined_dense = Dense(128)(combined_output)\n",
    "    combined_dense = LeakyReLU()(combined_dense)\n",
    "    \n",
    "    # Final output layer (for regression tasks, use linear activation; for classification, consider sigmoid/softmax)\n",
    "    final_output = Dense(1, activation='linear')(combined_dense)\n",
    "    \n",
    "    # Define the final model\n",
    "    model = Model(inputs=[structure_model.input, pattern_model.input, trigger_model.input, double_model.input],\n",
    "                  outputs=final_output)\n",
    "    \n",
    "    # Compile the model with mean squared error loss for regression tasks\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "def train_model(structure_data, pattern_data, trigger_data, double_data, target_data, input_shapes, model = None):\n",
    "    '''\n",
    "    Check if the model is already trained or partially trained. If not, build a new model. \n",
    "    Continue training the model and save the trained model to 'cnn_lstm_model.h5' after each session.\n",
    "\n",
    "    Args:\n",
    "        structure_data: Data for the structure timeframe.\n",
    "        pattern_data: Data for the pattern timeframe.\n",
    "        trigger_data: Data for the trigger timeframe.\n",
    "        double_data: Data for the double timeframe.\n",
    "        target_data: The labels or target values for training.\n",
    "        input_shapes: A dictionary containing the input shapes for structure, pattern, trigger, and double timeframe data.\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    '''\n",
    "    # Check if the model already exists, load if it does\n",
    "    model_path = 'cnn_lstm_model.h5'\n",
    "    \n",
    "    if model is None:\n",
    "        if os.path.exists(model_path):\n",
    "            print(\"Loading existing model from disk...\")\n",
    "            model = load_model(model_path)\n",
    "        else:\n",
    "            print(\"Building new model...\")\n",
    "            model = build_model(input_shapes)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([structure_data, pattern_data, trigger_data, double_data],\n",
    "                        target_data,\n",
    "                        epochs=10,\n",
    "                        batch_size=32)\n",
    "    print(history)\n",
    "    # Save the model after each training session to avoid losing progress\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved to disk.\")\n",
    "    \n",
    "    return model\n",
    "```"
   ],
   "id": "8976c18cf541c107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "22c671f910aa6071"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "structure_timeframes = {\n",
    "    '1W': {'pattern': '1D', 'trigger': '4h', 'double': '15min'},\n",
    "    '1D': {'pattern': '4h', 'trigger': '1h', 'double': '5min'},\n",
    "    '4h': {'pattern': '1h', 'trigger': '15min', 'double': '1min'}\n",
    "}\n",
    "\n",
    "\n",
    "def "
   ],
   "id": "96dace33290dc1cf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
