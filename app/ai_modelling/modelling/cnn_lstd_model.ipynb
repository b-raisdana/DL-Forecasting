{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:05:41.289521Z",
     "start_time": "2024-10-17T16:05:15.048657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from Config import config\n",
    "from helper.helper import date_range_to_string\n",
    "\n",
    "config.processing_date_range = date_range_to_string(start=pd.to_datetime('03-01-24'),\n",
    "                                                    end=pd.to_datetime('09-01-24'))\n",
    "# devided by rolling mean, std\n",
    "n_mt_ohlcv = pd.read_csv(\n",
    "    os.path.join(r\"C:\\Code\\dl-forcasting\\data\\Kucoin\\Spot\\BTCUSDT\",\n",
    "                 f\"n_mt_ohlcv.{config.processing_date_range}.csv.zip\"), parse_dates=['date'], compression='zip')\n",
    "n_mt_ohlcv.set_index(['timeframe', 'date'], inplace=True, drop=True)\n",
    "n_mt_ohlcv.dtypes, n_mt_ohlcv.index.dtypes"
   ],
   "id": "9caca9023e737e7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mDEBUG@\u001B[94m10-17.19:35:23:\u001B[92m...Starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(open      float64\n",
       " close     float64\n",
       " high      float64\n",
       " low       float64\n",
       " volume    float64\n",
       " dtype: object,\n",
       " timeframe                 object\n",
       " date         datetime64[ns, UTC]\n",
       " dtype: object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:05:42.182145Z",
     "start_time": "2024-10-17T16:05:41.514582Z"
    }
   },
   "cell_type": "code",
   "source": "n_mt_ohlcv.describe()",
   "id": "db6e26c4e54b9820",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                open          close           high            low  \\\n",
       "count  340668.000000  340668.000000  340668.000000  340668.000000   \n",
       "mean        0.002571       0.002537       0.000586       0.004814   \n",
       "std         1.080184       1.080047       1.081013       1.083676   \n",
       "min       -11.829250     -11.796538     -10.789105     -12.271370   \n",
       "25%        -0.556785      -0.557024      -0.575532      -0.531490   \n",
       "50%         0.010991       0.010835      -0.014932       0.036296   \n",
       "75%         0.575594       0.574331       0.553501       0.591531   \n",
       "max        13.730087      13.773854      13.686195      12.303279   \n",
       "\n",
       "              volume  \n",
       "count  340668.000000  \n",
       "mean        0.011528  \n",
       "std         1.070377  \n",
       "min        -4.911268  \n",
       "25%        -0.405402  \n",
       "50%        -0.136793  \n",
       "75%         0.143095  \n",
       "max        15.969589  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "      <td>340668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>0.011528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.080184</td>\n",
       "      <td>1.080047</td>\n",
       "      <td>1.081013</td>\n",
       "      <td>1.083676</td>\n",
       "      <td>1.070377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-11.829250</td>\n",
       "      <td>-11.796538</td>\n",
       "      <td>-10.789105</td>\n",
       "      <td>-12.271370</td>\n",
       "      <td>-4.911268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.556785</td>\n",
       "      <td>-0.557024</td>\n",
       "      <td>-0.575532</td>\n",
       "      <td>-0.531490</td>\n",
       "      <td>-0.405402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>-0.014932</td>\n",
       "      <td>0.036296</td>\n",
       "      <td>-0.136793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.575594</td>\n",
       "      <td>0.574331</td>\n",
       "      <td>0.553501</td>\n",
       "      <td>0.591531</td>\n",
       "      <td>0.143095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.730087</td>\n",
       "      <td>13.773854</td>\n",
       "      <td>13.686195</td>\n",
       "      <td>12.303279</td>\n",
       "      <td>15.969589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multi timeframe modelling\n",
    "\n",
    "\n",
    "structure_timeframes = {\n",
    "    '1W':{        pattern: '1D',        trigger: '4h',        double: '15min',    }, \n",
    "    '1D':{        pattern: '4h',        trigger: '1h',        double: '5min',    }, \n",
    "    '4h':{        pattern: '1h',        trigger: '15min',        double: '1min',    }, \n",
    "}\n",
    "n_mt_ohlcv include open, high, low, close, and volume of all timeframes.\n",
    "single_timeframe(n_mt_ohlcv, timeframe) will return data of specified timeframe.\n",
    "using tensorflow create 4 parallel CNN-LSTM models each fed with structure, pattern, trigger, and double timeframe data.\n",
    "join these parallel models together.\n"
   ],
   "id": "6427f865497c1ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:06:15.619624Z",
     "start_time": "2024-10-17T16:05:44.316292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "a1f1715472a3fc2b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check if model is not trained yet, try loading it from 'cnn_lstm_model.h5'. \n",
    "If it is already partially trained, or loaded from disk, continue training.\n",
    "after completing training on each set of data save model into 'cnn_lstm_model.h5' to prevent loosing data in case of computer restart.\n"
   ],
   "id": "8ce4bfcdb05bde50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:06:16.095056Z",
     "start_time": "2024-10-17T16:06:16.047880Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f9347e97cfa1de0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:09:44.411892Z",
     "start_time": "2024-10-17T16:08:58.238177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from training.trainer import mt_train_n_test\n",
    "\n",
    "X, y = mt_train_n_test('4h', n_mt_ohlcv, model_input_lengths, batch_size=10)\n",
    "X, y"
   ],
   "id": "47019696734b90b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mDEBUG@\u001B[94m10-17.19:39:22:\u001B[92m\"'t_open' in RollingMeanStdOHLCV but not in data:open           float64\\nclose          float64\\nhigh           float64\\nlow            float64\\nvolume         float64\\npre_open       float64\\nmean_open      float64\\nstd_open       float64\\nn_open         float64\\npre_close      float64\\nmean_close     float64\\nstd_close      float64\\nn_close        float64\\npre_high       float64\\nmean_high      float64\\nstd_high       float64\\nn_high         float64\\npre_low        float64\\nmean_low       float64\\nstd_low        float64\\nn_low          float64\\npre_volume     float64\\nmean_volume    float64\\nstd_volume     float64\\nn_volume       float64\\ndtype: object\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T15:32:10.362043Z",
     "start_time": "2024-10-12T15:32:10.350944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from training.trainer import plot_mt_train_n_test\n",
    "\n",
    "plot_mt_train_n_test(X, y, n=1, base)\n"
   ],
   "id": "11cbb99e2b29ee8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timeframe                 object\n",
       "date         datetime64[ns, UTC]\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f7a72c58508d78d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:18:45.320597Z",
     "start_time": "2024-10-12T17:21:28.998055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from training.trainer import mt_train_n_test\n",
    "\n",
    "a = mt_train_n_test('4h', n_mt_ohlcv, 10)\n",
    "a"
   ],
   "id": "c4fda4bf2a9b30c7",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'value_column'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\dl-forcasting\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'value_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 103\u001B[0m\n\u001B[0;32m     99\u001B[0m         nop \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(X), np\u001B[38;5;241m.\u001B[39marray(y)\n\u001B[1;32m--> 103\u001B[0m a \u001B[38;5;241m=\u001B[39m prepare_train_n_test(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m4h\u001B[39m\u001B[38;5;124m'\u001B[39m, n_mt_ohlcv, \u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m    104\u001B[0m a\n",
      "Cell \u001B[1;32mIn[31], line 77\u001B[0m, in \u001B[0;36mprepare_train_n_test\u001B[1;34m(t_structure_timeframe, mt_ohlcv, forecast_horizon, batch_size)\u001B[0m\n\u001B[0;32m     71\u001B[0m max_date \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(double_slice\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_level_values(level\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax(),\n\u001B[0;32m     72\u001B[0m                trigger_slice\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_level_values(level\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax(),\n\u001B[0;32m     73\u001B[0m                pattern_slice\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_level_values(level\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax(),\n\u001B[0;32m     74\u001B[0m                structure_slice\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_level_values(level\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax())\n\u001B[0;32m     76\u001B[0m \u001B[38;5;66;03m# Create traces for each slice\u001B[39;00m\n\u001B[1;32m---> 77\u001B[0m double_trace \u001B[38;5;241m=\u001B[39m go\u001B[38;5;241m.\u001B[39mScatter(x\u001B[38;5;241m=\u001B[39mdouble_slice\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_level_values(level\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m), y\u001B[38;5;241m=\u001B[39mdouble_slice[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue_column\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     78\u001B[0m                           mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDouble\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     79\u001B[0m trigger_trace \u001B[38;5;241m=\u001B[39m go\u001B[38;5;241m.\u001B[39mScatter(x\u001B[38;5;241m=\u001B[39mtrigger_slice\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_level_values(level\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     80\u001B[0m                            y\u001B[38;5;241m=\u001B[39mtrigger_slice[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue_column\u001B[39m\u001B[38;5;124m'\u001B[39m], mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrigger\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     81\u001B[0m pattern_trace \u001B[38;5;241m=\u001B[39m go\u001B[38;5;241m.\u001B[39mScatter(x\u001B[38;5;241m=\u001B[39mpattern_slice\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_level_values(level\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     82\u001B[0m                            y\u001B[38;5;241m=\u001B[39mpattern_slice[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue_column\u001B[39m\u001B[38;5;124m'\u001B[39m], mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPattern\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dl-forcasting\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dl-forcasting\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'value_column'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "structure_timeframes = {\n",
    "    '1W': {'pattern': '1D', 'trigger': '4h', 'double': '15min'},\n",
    "    '1D': {'pattern': '4h', 'trigger': '1h', 'double': '5min'},\n",
    "    '4h': {'pattern': '1h', 'trigger': '15min', 'double': '1min'}\n",
    "}\n",
    "loop over structure timeframe in ['1D', '4h']:\n",
    "collect information from already prepared function read_ohlcv_features(start, end, timeframe)\n",
    "create required iteration to pass data to train_model\n",
    "choose double_timeframe_end in the range of start and end\n",
    "structure_timeframe_end= structure_timeframe_end = trigger_timeframe_end = double_timeframe_end\n",
    "calculate trigger_timeframe_start according to trigger_timeframe_end and number of bars shall be passed for taining 'trigger_model' \n",
    "calculate pattern_timeframe_start according to pattern_timeframe_end and number of bars shall be passed for taining 'pattern_model' \n",
    "calculate structure_timeframe_start according to structure_timeframe_end and number of bars shall be passed for taining 'structure_model' \n",
    "\n",
    "for:\n",
    "```python\n",
    "def create_cnn_lstm(input_shape, name_prefix):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN Layer with ReLU activation\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(input_layer)\n",
    "    conv = LeakyReLU()(conv)\n",
    "    conv = Conv1D(filters=64, kernel_size=3, padding='same')(conv)\n",
    "    conv = LeakyReLU()(conv)\n",
    "\n",
    "    # Flatten the CNN output\n",
    "    flatten = Flatten()(conv)\n",
    "\n",
    "    # LSTM Layer (LSTM has built-in activations)\n",
    "    lstm = LSTM(64, return_sequences=False)(tf.expand_dims(flatten, axis=1))\n",
    "\n",
    "    # Fully connected layer with ReLU activation\n",
    "    dense = Dense(64)(lstm)\n",
    "    dense = LeakyReLU()(dense)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=dense)\n",
    "\n",
    "def build_model(input_shapes):\n",
    "    structure_model = create_cnn_lstm((128, 5), 'structure_model')\n",
    "    pattern_model = create_cnn_lstm((256, 5), 'pattern_model')\n",
    "    trigger_model = create_cnn_lstm((256, 5), 'trigger_model')\n",
    "    double_model = create_cnn_lstm((256, 5), 'double_model')\n",
    "    \n",
    "    combined_output = Concatenate()(\n",
    "        [structure_model.output, pattern_model.output, trigger_model.output, double_model.output])\n",
    "    \n",
    "    # Add an additional Dense layer with ReLU activation\n",
    "    combined_dense = Dense(128)(combined_output)\n",
    "    combined_dense = LeakyReLU()(combined_dense)\n",
    "    \n",
    "    # Final output layer (for regression tasks, use linear activation; for classification, consider sigmoid/softmax)\n",
    "    final_output = Dense(1, activation='linear')(combined_dense)\n",
    "    \n",
    "    # Define the final model\n",
    "    model = Model(inputs=[structure_model.input, pattern_model.input, trigger_model.input, double_model.input],\n",
    "                  outputs=final_output)\n",
    "    \n",
    "    # Compile the model with mean squared error loss for regression tasks\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "def train_model(structure_data, pattern_data, trigger_data, double_data, target_data, input_shapes, model = None):\n",
    "    '''\n",
    "    Check if the model is already trained or partially trained. If not, build a new model. \n",
    "    Continue training_data the model and save the trained model to 'cnn_lstm_model.h5' after each session.\n",
    "\n",
    "    Args:\n",
    "        structure_data: Data for the structure timeframe.\n",
    "        pattern_data: Data for the pattern timeframe.\n",
    "        trigger_data: Data for the trigger timeframe.\n",
    "        double_data: Data for the double timeframe.\n",
    "        target_data: The labels or target values for training_data.\n",
    "        input_shapes: A dictionary containing the input shapes for structure, pattern, trigger, and double timeframe data.\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    '''\n",
    "    # Check if the model already exists, load if it does\n",
    "    model_path = 'cnn_lstm_model.h5'\n",
    "    \n",
    "    if model is None:\n",
    "        if os.path.exists(model_path):\n",
    "            log_d(\"Loading existing model from disk...\")\n",
    "            model = load_model(model_path)\n",
    "        else:\n",
    "            log_d(\"Building new model...\")\n",
    "            model = build_model(input_shapes)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit([structure_data, pattern_data, trigger_data, double_data],\n",
    "                        target_data,\n",
    "                        epochs=10,\n",
    "                        batch_size=32)\n",
    "    log_d(history)\n",
    "    # Save the model after each training_data session to avoid losing progress\n",
    "    model.save(model_path)\n",
    "    log_d(\"Model saved to disk.\")\n",
    "    \n",
    "    return model\n",
    "```"
   ],
   "id": "8976c18cf541c107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "22c671f910aa6071"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "structure_timeframes = {\n",
    "    '1W': {'pattern': '1D', 'trigger': '4h', 'double': '15min'},\n",
    "    '1D': {'pattern': '4h', 'trigger': '1h', 'double': '5min'},\n",
    "    '4h': {'pattern': '1h', 'trigger': '15min', 'double': '1min'}\n",
    "}\n",
    "\n",
    "\n",
    "def "
   ],
   "id": "96dace33290dc1cf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
